---
layout: page
title: Haohe Liu åˆ˜æ¿ èµ« (Leo) 
permalink: /

    # - title: "Centre for Vision, Speech and Signal Processing @ University of Surrey, UK, 01/2022 - 01/2025"
    #   image: "/images/surrey_logo_2.png"
    #   comment: "-- PhD in Vision, Speech and Signal Processing | Main advisor: [Prof. Mark D. Plumbley]<br/>
    #             -- With a studentship from the CVSSP"   
                
education:
    - title: "Centre for Vision, Speech and Signal Processing @ University of Surrey, UK, 01/2022 - 01/2025"
      image: "/images/surrey_logo.png"
      comment: "-- PhD in Vision, Speech and Signal Processing; Main advisor: [Prof. Mark D. Plumbley]<br/>
                -- With a studentship from the CVSSP and the EPSRC Grant EP/T019751/1 AI for Sound"
    # - title: "Department of Computer Science and Engineering @ The Ohio State University, US, 01/2021 - 01/2022"
    #   image: "images/Ohio_State_University_seal.svg.png"
    #   comment: "-- PhD in Artificial Intelligence, Quit; advisor: [Prof. DeLiang Wang]<br/>
    #             -- GPA: 4.0/4.0"
    - title: "School of Computer Science @ Northwestern Polytechnical University, China, 09/2016 - 07/2020"
      image: "/images/nwpu.png"
      comment: "-- Bachelor of Engineering, Outstanding graduate, Computer Science and Technology; Advisor: [Prof. Lei Xie]<br/>
                -- GPA: 3.8/4.0 (Top 5%)"

interns:
    - title: "Microsoft Research Asia, Beijing, 10/2021 - 04/2022"
      image: "/images/microsoft-logo.png"
      comment: "-- Topic: Text-to-Speech Synthesis with human parity<br/>
                -- Mentor: [Xu Tan]; Research output: [NaturalSpeech], etc. "
                
    - title: "ByteDance, Speech, Audio and Music Intelligence, Shanghai, 07/2020-10/2021"
      image: "/images/bytedance-logo.png"
      comment: "-- Topics: Speech Enhancement; Music Source Separation; General Speech Quality Enhancement; Speech Super-resolution<br/>
                -- Mentor: [Qiuqiang Kong]; Research output: [VoiceFixer], [CWS-PResUNet], [NVSR], etc. All code are open-sourced. "

competitions:
    - title: First place
      author:  "Yi Yuan, **Haohe Liu**, Xubo Liu, Xiyuan Kang, Mark D.Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 7:Foley Sound Synthesis"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  "https://dcase.community/documents/challenge2023/technical_reports/DCASE2023_Yi_67_t7.pdf"
        - name: "Demo"
          url: "https://yyua8222.github.io/dcase_2023_t7_demo/"
        - name: "Code"
          url: "https://github.com/yyua8222/Dcase2023_task7"
        - name: "leaderboard"
          url: "https://dcase.community/challenge2023/task-foley-sound-synthesis-results"  
          
    - title: Second place
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE Challenge Task 5:Few-shot Bioacoustic Event Detection"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2207.07773
        - name: "Code"
          url: "https://github.com/haoheliu/DCASE_2022_Task_5"
        - name: "leaderboard"
          url: "https://dcase.community/challenge2022/task-few-shot-bioacoustic-event-detection-results"  

    - title: Second place on vocal score and fifth place on overall score
      author:  "**Haohe Liu** and Qiuqiang Kong and Jiafeng Liu"
      journal: "ISMIR Music Demixing Challenge"
      year:    "2021"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2112.04685
        - name: "Code"
          url: "https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet"
        - name: "Challenge details"
          url: "https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021"
        - name: "leaderboard"
          url: "https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards"    

    - title: Second place
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 6B: Language-Based Audio Retrieval"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_118_t6b.pdf
        - name: "Challenge details"
          url: "https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval" 

    - title: Third place
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 6A: Automated Audio Captioning"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf
        - name: "Challenge details"
          url: "https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval" 

# projects:
#     - title: EPSRC Grant EP/T019751/1 "[AI for Sound]"
#       time:  "01/2022 - now"
#       topic: "New AI for sound technology has major potential applications in security, health & wellbeing, environmental sensing, urban living, and the creative sector."
#       comment: "The goal of my research is to develop new methods for automatic labeling of sound environments and events in broadcast audio, assisting production staff to find and search through content, and helping the general public access archive content."
#       image: "/images/AI4SOUND-logo.png"

# activities:
#     - title: "Vice President | Tencent Innovation Club"
#       year:  "10/2016 - 07/2019"
#       image: "/images/tic.jpg"
#       comment: "-- 2016-2017, served as the leader of the WeChat team, and was awarded the best team of the year <br/>
#                 -- 2017-2018, served as the director of the club's network advertising department, was awarded the outstanding member of the annual Tencent Innovation Club <br/>
#                 -- Achieved the first place (1/21) in the competition of college clubs affiliated to Tencent Inc in 2017<br/>"
                
#     - title: "Chief Propagandist & Technical Support | Summer Social Practice Activities"
#       year:  "07/2017"
#       image: "/images/share.jpg"
#       comment: "-- Participated in the school-level summer social practice activities <br/> 
#                 -- Research Objective: the current situation and future prospects of Guangzhou's shared economy<br/> 
#                 -- Responsible for advertising, filming and video editing<br/>"

#     - title: "Minister of Public Relations Department | Computer Volunteer Service Team"
#       year:  "10/2016 - 10/2018"
#       image: "/images/volunteer.jpg"
#       comment: "-- Provided computer maintenance service for students and teachers for free <br/> 
#                 -- Connected community organizations to organize and arrange free computer maintenance activities"

news:
    shown:
      - time: 2023-06-10 	&#128745;
        note: Attended ICASSP 2023 (Rhodes, Greece)!
      - time: 2023-06-02 &#128227;
        note: Rank 1st place in DCASE Challenge 2023 Task 7 - Foley Sound Synthesis.
      - time: 2023-05-18 &#128227;
        note: Three papers are accepted by INTERSPEECH 2023!
      - time: 2023-05-11 &#128100;
        note: Visit Department of Engineering, University of Cambridge, UK, for presentation and discussions.
      - time: 2023-04-25 &#128227;
        note: AudioLDM is accepted by ICML, International Conference on Machine Learning.
      - time: 2023-04-14 &#128100;
        note: Remotely present my recent research to Chinese Academy of Science (ä¸­ç§‘é™¢å£°å­¦æ‰€)
      - time: 2023-04-10 &#128100;
        note: Remotely present my recent research to Gaoling School of Artificial Intelligence, Remin University of China (ä¸­å›½äººæ°‘å¤§å­¦é«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢)
      - time: 2023-03-08 &#128100;
        note: Gave a remote presentation about AudioLDM to Mila, University of montreal [<a href="https://www.youtube.com/watch?v=6qtL9_T8m3c&t=972s">link to recording</a>]
      - time: 2023-02-28 &#127775;
        note: Youtube coverage of AudioLDM [<a href="https://www.youtube.com/watch?v=_0VTltNYhao&list=LL&index=2k">link</a>]. Comment area is very interesting. Thanks MattVidPro AI!
      - time: 2023-02-26 &#127775;
        note: Github repos reach 2000 stars in total!
      - time: 2023-02-24 &#128100;
        note: Gave a remote presentation about AudioLDM to SAMI, ByteDance, China. Thanks Qiuqiang for the invitation!
      - time: 2023-02-23 &#127775;
        note: AudioLDM ranks Top 25 most liked space (Top 0.01%) on Hugging Face [<a href="https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation">link</a>].        
      - time: 2023-02-22 &#128100;
        note: Gave a presentation about AudioLDM at TikTok, London. Thanks Janne for organizing this event!
      - time: 2023-02-17 &#128100;
        note: Gave a remote presentation about AudioLDM to NetEase, China. Thanks Pengcheng for the invitation!
      - time: 2023-02-15 &#128100;
        note: Live steaming and presenting AudioLDM on WeChat (in Chinese), with 4000+ viewers! [<a href="pdf/AudioLDM_2023_02_15.pdf">slides</a>]
      - time: 2023-02-15 &#128227;
        note: A paper was accepted in ICASSP 2023.
      - time: 2023-02-13 &#128227;
        note: A Large Chinese Media (æœºå™¨ä¹‹å¿ƒ) report our AudioLDM [<a href="https://mp.weixin.qq.com/s/UlkAVWYNrkMGNqtoDuMAGQ">link</a>]
      - time: 2023-02-03 &#127775;
        note: AI album [<a href="https://www.latent.store/albums ">website</a>], generated by our proposed text-to-audio generation model AudioLDM!
    hidden:
      - time: 2022-11-03 	&#128745;
        note: Attend DCASE 2022 Workshop (Nancy, France)!
      - time: 2022-09-18 	&#128745;
        note: Attend INTERSPEECH 2022 (Incheon, Korea) remotely and present two papers!
      - time: 2022-09-16 &#128227;
        note: A paper was accepted in NeurIPS 2022.
      - time: 2022-09-15 &#128227;
        note: A paper was accepted in DCASE Workshop 2022.

      - time: 2022-07-01 &#128227;
        note: Great result in DCASE 2022 Challenge - 2nd in Task 5; 2nd in Task 6B; 3rd in Task 6A.
      - time: 2022-06-01 &#128227;
        note: Four papers were accepted in INTERSPEECH 2022.
      - time: 2022-05-15 &#128227;
        note: A papers was accepted in EUSIPCO 2022. 
      - time: 2021-11-12 &#128100;
        note: Presented our winner model CWS-PResUNet to the audience on 2021 ISMIR MDX workshop.
      - time: 2021-11-12 &#128100;
        note: Gave a tutorial talk (<a href="https://docs.google.com/presentation/d/1AnlvPYCcuUZ2AW-4Q4BNdakqzgajoe9ltr4QUAr2oWw/edit">slides</a>) on music source separation with Alexandre Defossez and Woosung Choi at the 2021 ISMIR MDX satellite event!
      - time: 2021-10-26 &#128187;
        note: Joined the Microsoft Research Asia as a research intern.
      - time: 2021-09-30 &#128100;
        note: Gave a talk on VENTURE å°†é—¨åˆ›æŠ• (In Chinese) about the voicefixer I developed recently! [<a href="https://www.techbeat.net/talk-info?id=586">link</a>]
      - time: 2021-08-19 &#128195;
        note: Accept the Ph.D. offer from the CVSSP, University of Surrey, with tuition fee waiver and stipend!
      - time: 2021-07-31 &#128227;
        note: Great result in 2021 MDX Challenge (41 teams and 609 participants in total) - 2nd in vocal separation score; 5th in overall score; 
      - time: 2021-07-09 &#128227;
        note: A paper was accepted in ISMIR 2021.
      - time: 2021-06-02 &#128227;
        note: A paper was accepted in INTERSPEECH 2021.
      - time: 2020-07-27 &#128187;
        note: Joined the ByteDance AI lab as a research intern.
      - time: 2020-07-24 &#128227;
        note: A paper was accepted in INTERSPEECH 2020.
      - time: 2020-07-12 &#127891;
        note: Graduated from Northwestern Polytechnical University with a bachelor's degree and outstanding graduate award!
      - time: 2020-01-21 &#128195;
        note: Accept a Ph.D. offer from the Ohio State University!

pubs:
    - title: "ðŸ‘¤ AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining"
      author:  "**Haohe Liu**, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley"
      journal: "arXiv preprint arXiv:2308.05734"
      year:    "2023"
      images:  
        - caption: "Architecture"
          url: "images/audioldm2.jpg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2308.05734
        - name: "Code"
          url: https://github.com/haoheliu/audioldm2
        - name: "Project Page"
          url: https://audioldm.github.io/audioldm2/
        - name: "HuggingFace Web Demo"
          url: https://huggingface.co/spaces/haoheliu/audioldm2-text2audio-text2music
        - name: "Discord Community"
          url: https://discord.gg/b64SEmdf

    - title: "Separate Anything You Describe"
      author:  "Xubo Liu, Qiuqiang Kong, Yan Zhao, **Haohe Liu**, Yi Yuan, Yuzhuo Liu, Rui Xia, Yuxuan Wang, Mark D Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv:2308.05037"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2308.05037
        - name: "Code"
          url:  https://github.com/Audio-AGI/AudioSep
        - name: "Project Page; Demo"
          url:  https://audio-agi.github.io/Separate-Anything-You-Describe/
          
    - title: "WavJourney: Compositional Audio Creation with Large Language Models"
      author:  "Xubo Liu, Zhongkai Zhu, **Haohe Liu**, Yi Yuan, Meng Cui, Qiushi Huang, Jinhua Liang, Yin Cao, Qiuqiang Kong, Mark D Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv:2307.14335"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2307.14335
        - name: "Code"
          url:  https://github.com/Audio-AGI/WavJourney
        - name: "Project Page; Demo"
          url:  https://audio-agi.github.io/WavJourney_demopage/

    - title: "Text-Driven Foley Sound Generation With Latent Diffusion Model"
      author:  "Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark D Plumbley, Wenwu Wang"
      journal: "DCASE Workshop 2023"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2306.10359

    - title: "Universal Source Separation with Weakly Labelled Data"
      author:  "Qiuqiang Kong, Ke Chen, **Haohe Liu**, Xingjian Du, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Mark D. Plumbley"
      journal: "arXiv preprint arXiv:2305.07447"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2305.07447
        - name: "code"
          url: https://github.com/bytedance/uss

    - title: "E-PANNs: Sound Recognition Using Efficient Pre-trained Audio Neural Networks"
      author:  "Arshdeep Singh, **Haohe Liu**, Mark D Plumbley"
      journal: "arXiv preprint arXiv:2305.18665"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2305.18665

    - title: "Learning to Detect an Animal Sound from Five Examples"
      author:  "InÃªs Nolasco, Shubhr Singh, Veronica Morfi, Vincent Lostanlen, Ariana Strandburg-Peshkin, Ester VidaÃ±a-Vila, Lisa Gill, Hanna PamuÅ‚a, Helen Whitehead, Ivan Kiskin, Frants H Jensen, Joe Morford, Michael G Emmerson, Elisabetta Versace, Emily Grout, **Haohe Liu**, Dan Stowell"
      journal: "Ecological Informatics"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2305.13210

    - title: "WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research"
      author:  "Xinhao Mei, Chutong Meng, **Haohe Liu**, Qiuqiang Kong, Tom Ko, Chengqi Zhao, Mark D. Plumbley, Yuexian Zou, Wenwu Wang"
      journal: "arXiv preprint arXiv:2303.17395"
      year:    "2023" 
      images:  
        - caption: "How we built the WavCaps"
          url: "images/wavcaps.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2303.17395
        - name: "Dataset Download"
          url: https://github.com/XinhaoMei/WavCaps

    - title: "ðŸ‘¤ Leveraging Pre-trained AudioLDM for Sound Generation: A Benchmark Study"
      author:  "Yi Yuan\\*, **Haohe Liu**\\*, Jinhua Liang, Xubo Liu, Mark D. Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv: 2303.03857"
      year:    "2023" 
      images:  
        - caption: "Finetune on ESC50"
          url: "images/audioldm-esc50.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2303.03857

    - title:   "ðŸ‘¤ AudioLDM: Text-to-Audio Generation with Latent Diffusion Models"
      author:  "**Haohe Liu**\\*, Zehua Chen\\*, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley"
      journal: "International Conference on Machine Learning (ICML)"
      year:    "2023" 
      images:  
        - caption: "Model Architecture"
          url: "/images/AudioLDM-main.jpg"
      media:
        - name: "Page"
          url:  https://audioldm.github.io/
        - name: "Paper"
          url:  https://arxiv.org/abs/2301.12503
        - name: "arXiv"
          url: https://arxiv.org/abs/2207.02201
        - name: "Code"
          url: https://github.com/haoheliu/AudioLDM
        - name: "Evaluation Code"
          url: https://github.com/haoheliu/audioldm_eval
        - name: "Hugging Face Space"
          url: https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation
        - name: "Replicate API"
          url: https://replicate.com/haoheliu/audio-ldm 
        - name: "Others"
          url: "https://docs.google.com/document/d/1ZM6r3ZtJ4mdtsYaTtUSG3_LaiaSCUxvCf8UvCE2HRls/edit?usp=sharing"
      additional: 
        - content: "2023-03-08 AudioLDM have reached 1000 stars on Github!"
        - content: "2023-03-09 AudioLDM reaches 400 likes on Hugging Face! Currently rank the TOP 25 liked spaces!"

    - title:   "Adapting Language-Audio Models as Few-Shot Audio Learners"
      author:  "Jinhua Liang, Xubo Liu, **Haohe Liu**, Huy Phan, Emmanouil Benetos, Mark D. Plumbley, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      # media:
      #   - name: "Paper"
      #     url:  https://arxiv.org/abs/2210.16428

    - title:   "ðŸ‘¤ Ontology-aware Learning and Evaluation for Audio Tagging"
      author:  "**Haohe Liu**, Qiuqiang Kong, Xubo Liu, Xinhao Mei, Wenwu Wang, Mark D. Plumbley"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      images: 
        - caption: "Main idea"
          url: "images/ontology-based-map.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2211.12195

    - title:   "Visually-awared Audio Captioning with Adaptive Audio-Visual Attention"
      author:  "Xubo Liu\\*, Qiushi Huang\\*, Xinhao Mei\\*, **Haohe Liu**, Qiuqiang Kong, Jianyuan Sun, Ko Tom, Yu Zhang, Lilian H. Tang, Mark D. Plumbley, Volkan KÄ±lÄ±c4, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2210.16428

    - title:   "Simple Pooling Front-ends For Efficient Audio Classification"
      author:  "Xubo Liu, **Haohe Liu**, Qiuqiang Kong, Xinhao Mei, Mark D. Plumbley, Wenwu Wang"
      journal: "IEEE International Conference on Acoustics, Speech, and Signal Processing"
      year:    "2023"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2210.00943

    - title:   "ðŸ‘¤ Learning the Spectrogram Temporal Resolution for Audio Classification"
      author:  "**Haohe Liu**, Xubo Liu, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "arXiv preprint arXiv:2210.01719"
      year:    "2022"
      images:   
        - caption: "DiffRes Architecture"
          url: "/images/diffres.png"
      media:
        - name: "Paper"
          url:  "https://arxiv.org/abs/2210.01719"
        - name: "Code"
          url:  https://github.com/haoheliu/diffres-python

    - title:   "ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech"
      author:  "Zehua Chen, Yihan Wu, Yichong Leng, Jiawei Chen, **Haohe Liu**, Xu Tan, Yang Cui, Ke Wang, Lei He, Sheng Zhao, Jiang Bian, Danilo Mandic"
      journal: "arXiv preprint arXiv:2212.14518"
      year:    "2022"
      images:
        - caption: "Pipline"
          url: "images/DiffSkinpipeline.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2212.14518"
        - name: "Demo"
          url: "https://resgrad1.github.io/"  

    - title:   "ðŸ‘¤ Surrey System for DCASE 2022 Task 5: Few-shot Bio-acoustic Event Detection with Segment-level Metric Learning"
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 2nd place in DCASE 2022 Challenge Task 5:Few-shot Bioacoustic Event Detection."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Haohe_85_5.pdf

    - title:   "Automated Audio Captioning with Keywords Guidance"
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 3rd place in DCASE 2022 Challenge Task 6A: Automated Audio Captioning."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf
      additional:
        - content: "System based on this method ranks 3nd in DCASE 2022 Challenge Task 6A"

    - title:   "Language-Based Audio Retrieval with Pre-trained Models"
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 3rd place in DCASE 2022 Challenge Task 6B: Language-Based Audio Retrieval."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_118_t6b.pdf
      additional:
        - content: "System based on this method ranks 2nd in DCASE 2022 Challenge Task 6B"


    - title:   "ðŸ‘¤ Segment-level Metric Learning for Few-shot Bioacoustic Event Detection"
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE Workshop 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      images: 
        - caption: "Framework"
          url: "images/dcase2022_main.png"
        - caption: "Ranking"
          url: "images/dcase2022_t5.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2207.07773
        - name: "Code"
          url: "https://github.com/haoheliu/DCASE_2022_Task_5"
      additional:
        - content: "System based on this method ranks 2nd in DCASE 2022 Challenge Task 5"

    - title:   "BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis"
      author:  "Yichong Leng, Zehua Chen, Junliang Guo, **Haohe Liu**, Jiawei Chen, Xu Tan, Danilo Mandic, Lei He, Xiang-Yang Li, Tao Qin, Sheng Zhao, Tie-Yan Liu"
      journal: "Conference on Neural Information Processing Systems (NeurIPS)"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      images: 
        - caption: "Model Architecture"
          url: "images/BinarualGrad.png"
      media:
        - name: "Page"
          url:  https://speechresearch.github.io/binauralgrad/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2205.14807" #"https://doi.org/10.1109/TCSVT.2022.3143151"

    - title:   "ðŸ‘¤ NaturalSpeech: End-to-End Text-to-Speech Synthesis with Human-Level Quality"
      author:  "Xu Tan\\*, Jiawei Chen\\*, Haohe Liu\\*, Jian Cong, Chen Zhang, Yanqing Liu, Xi Wang, Yichong Leng, Yuanhao Yi, Lei He, Frank Soong, Tao Qin, Sheng Zhao, Tie-Yan Liu"
      journal: "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)"
      year:    "2022"
      note: under review
      # image:   "/images/no.svg"
      images:
        - caption: "Model Architecture"
          url: "images/NaturalSpeech.png"
      media:
        - name: "Page and demo"
          url:  https://speechresearch.github.io/naturalspeech/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2205.04421" #"https://doi.org/10.1109/TCSVT.2022.3143151"

    - title:   "ðŸ‘¤ VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration"
      author:  "**Haohe Liu**\\*, Xubo Liu\\*, Qiuqiang Kong, Qiao Tian, Yan Zhao, Deliang Wang, Chuanzeng Huang, Yuxuan Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Page"
          url:  https://haoheliu.github.io/demopage-voicefixer/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2204.05841"
        - name: "Code"
          url:  "https://github.com/haoheliu/voicefixer"         

    - title:   "ðŸ‘¤ VoiceFixer: Toward General Speech Restoration with Neural Vocoder"
      author:  "**Haohe Liu**, Qiuqiang Kong, Qiao Tian, Yan Zhao, Deliang Wang, Chuanzeng Huang, Yuxuan Wang"
      journal: "arXiv preprint arXiv:2109.13731"
      year:    "2021"
      doi:     
      images:   
        - caption: "VoiceFixer Architecture"
          url: "images/VoiceFixer.png"
      media:
        - name: "Page"
          url:  https://haoheliu.github.io/demopage-voicefixer/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2204.05841"
        - name: "Code"
          url:  "https://github.com/haoheliu/voicefixer"  
      additional: 
        - content: "2023-03-02 VoiceFixer reaches 400 stars on Github!"

    - title:   "ðŸ‘¤ Neural Vocoder is All You Need for Speech Super-resolution"
      author:  "**Haohe Liu**, Woosung Choi, Xubo Liu, Qiuqiang Kong, Qiao Tian, DeLiang Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      images:
        - caption: "Architecture"
          url: "images/nvsr-main.png"
        - caption: "Example"
          url: "images/nvsr-example.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.15147"
        - name: "Code"
          url: "https://github.com/haoheliu/ssr_eval"

    - title:   "Multiple Speakers Tracking with Audio and Visual Signals"
      author:  "Jinzheng Zhao, Peipei Wu, Xubo Liu, Shidrokh Goudarzi, **Haohe Liu**, Yong Xu, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      media:
        - name: "Paper"
          url:  "http://personal.ee.surrey.ac.uk/Personal/W.Wang/papers/ZhaoWLGLXW_INTERSPEECH_2022.pdf"

    - title:   "Separate What You Describe: Language-Queried Audio Source Separation"
      author:  "Xubo Liu, **Haohe Liu**, Qiuqiang Kong, Xinhao Mei, Jinzheng Zhao, Qiushi Huang, Mark D. Plumbley, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      images:
        - caption: "Framework"
          url: "images/LASS-main.png"
        - caption: "Example"
          url: "images/LASS-example.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.15147"
        - name: "Code"
          url: "https://github.com/liuxubo717/LASS"

    - title:   "Leveraging Pre-trained BERT for Audio Captioning"
      author:  "Xubo Liu, Xinhao Mei, Qiushi Huang, Jianyuan Sun, Jinzheng Zhao, **Haohe Liu**, Mark D. Plumbley, Volkan KÄ±lÄ±c, Wenwu Wang"
      journal: "EUSIPCO"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.02838"

    - title:   "ðŸ‘¤ CWS-PResUNet: Music Source Separation with Channel-wise Subband Phase-aware ResUNet"
      author:  "**Haohe Liu** and Qiuqiang Kong and Jiafeng Liu"
      journal: "ISMIR Music Demixing Workshop"
      year:    "2021"
      doi:     
      images:   
        - caption: "Ranking" 
          url: "images/ismir_challenge_ranks.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2112.04685"
      additional:
        - content: "Ranking in 2021 ISMIR Music Demixing Challenge (611 participants): vocal score (2nd), overall performance (5th). "

    - title:   "Decoupling Magnitude and Phase Estimation with Deep ResUNet for Music Source Separation"
      author:  "Qiuqiang Kong, Yin Cao, **Haohe Liu**, Keunwoo Choi, Yuxuan Wang"
      journal: "ISMIR"
      year:    "2021"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2109.05418"

    - title:   "Speech Enhancement with weakly labeled data from audioset"
      author:  "Qiuqiang Kong, **Haohe Liu**, Xingjian Du, Li Chen, Rui Xia, Yuxuan Wang"
      journal: "INTERSPEECH"
      year:    "2021"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2008.05216"


    - title:   "ðŸ‘¤ Channel-wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music"
      author:  "**Haohe Liu**, Lei Xie, Jian Wu, Geng Yang"
      journal: "INTERSPEECH"
      year:    "2020"
      doi:     
      images:   
        - caption: "Motivation"
          url: "images/cws-intuition.png"
        - caption: "Architecture"
          url: "images/cws-architecture.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2102.09971"
        - name: "Code"
          url: "https://github.com/haoheliu/Subband-Music-Separation"
        - name: "Demo"
          url: "https://haoheliu.github.io/Channel-wise-Subband-Input/"

---

<!-- About me -->

[![GitHub stars](https://img.shields.io/github/stars/haoheliu?style=social)](https://github.com/haoheliu) &nbsp;&nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/LiuHaohe?style=social)](https://twitter.com/LiuHaohe) &nbsp;&nbsp; [![LinkedIn](https://img.shields.io/badge/-LinkedIn-black.svg?style=flat-square&logo=linkedin&colorB=0077B5)](https://www.linkedin.com/in/haohe-liu-4483a71a4/) &nbsp;&nbsp; [![Google Scholar](https://img.shields.io/badge/Google-Scholar-blue?style=flat-square&logo=google-scholar)](https://scholar.google.com/citations?user=g3O4lJMAAAAJ)

Email: *haohe.liu AT surrey dot ac dot uk*

Pronounciation of Haohe: <span style="font-family: &quot;Doulos SIL&quot;, sans-serif; font-style: italic;">|hÉ‘ÊŠ'hÉ™|</span> (the same "he" as "hello")


{% include image.html url="images/longmen.jpg" caption="Shot at Longmen Grottoes in China" width="190px" align="right" %}

Iâ€™m Haohe Liu, a Ph.D. student at the [Centre for Vision Speech and Signal Processing] (CVSSP), University of Surrey. My research includes topics related to speech, music, and general audio. I am fortunate to be advised by [Prof. Mark D. Plumbley], co-supervised by [Prof. Wenwu Wang]. And Iâ€™m lucky to be jointly funded by [BBC R&D] and the Doctoral College. Most of my studies are open-sourced. Currently, I'm working on text-to-general-audio generation, with more emphasis on better quality, controllability, immersivity, and text relevancy. I have served as a reviewer for INTERSPEECH and ACM multimedia. 

<!-- In the CVSSP, Iâ€™m working as part of the [AI for Sound] project with the goal of developing new methods for automatic labeling of sound environments and events in broadcast audio, assisting production staff to find and search through content, and helping the general public access archive content.  -->
<!-- Iâ€™m also working closely with BBC R&D Audio Team on putting our audio recognition algorithms into production, such as generating machine tags in [BBC sound effect library]. -->

**I'm open to research and cooperations on related topics. Feel free to drop me an email.**

<!-- <font color='#318CE7'><b>- I am looking for a job opportunity about 3DVision, free to contact me if you think we are a good match.</b></font> -->

## Research highlights
My research include tasks related with audio generative model, audio source separation, audio quality enhancement, audio recognition.

Highlighted research as the first author:

- State-of-the-art text-to-audio generation model: [AudioLDM].
- First text-to-speech model that achieves on par CMOS with human recording: [NaturalSpeech].
- Restore the quality of human speech signal regardless how the signal is degraded: [VoiceFixer].
- The music source separation system that achieves leading performance on Music Demixing Challenge 2021: [CWS-PResUNet].
- State-of-the-art speech super-resolution model: [NVSR].
- A module that make temporal-resolution of the spectrogram differentiable for efficient audio classificaiton: [DiffRes].
- Few-shot bioacoustic detection: The 2rd ranking system in the [DCASE 2022 Challenge] Task 5.

**Check out my [papers gallery](#papers){:target="_self"} for more information.**

## Recent News
<ul>
  {% for new in page.news.shown %}
    <li> {{new.time}} {{new.note}} </li>
  {% endfor %}
  <span id="points">...</span>
  <span id="moreText"> 
    {% for new in page.news.hidden %}
      <li> {{new.time}} {{new.note}} </li>
    {% endfor %}
  </span>
</ul>
<button onclick="toggleText()" id="textButton" class="showbutton"> Show More </button>

## Education and Intern Experience

{% assign thumbnail="left" %}
{% for edu in page.education %}
{% if edu.image %}
{% include image_original.html url=edu.image caption="" width="70px" align=thumbnail %}
{% endif %}
**{{edu.title}}** <br/>
{{ edu.comment }}
{% endfor %}

{% for intern in page.interns %}
{% if intern.image %}
{% include image_original.html url=intern.image caption="" width="70px" align=thumbnail %}
{% endif %}
**{{intern.title}}** <br/>
{{ intern.comment }}
{% endfor %}<br/>

## Competitions
<!-- - Second place in DCASE 2022 Challenge Task 5:Few-shot Bioacoustic Event Detection. [code][details][leaderboard]
- Second place on vocal score and fifth place on overall score in ISMIR 2021 Music Demixing Challenge. [code][details] [leaderboard]
- Third in DCASE 2022 Challenge Task 6A: Automated Audio Captioning.
- Third in DCASE 2022 Challenge Task 6B: Language-Based Audio Retrieval. -->

{% assign thumbnail="left" %}
{% for comp in page.competitions %}
{% if comp.image %}
{% include image.html url=comp.image caption="" height="100px" align=thumbnail %}
{% endif %}
<!-- [**{{pub.title}}**]({% if pub.internal %}{{pub.url | prepend: site.baseurl}}{% else %}{{pub.url}}{% endif %})<br /> -->
- **{{comp.title}}**, *{{comp.journal}}*, {% if comp.year %} *{{comp.year}}* {% endif %}<br />
{{comp.author}}<br />
<!-- {% if comp.note %} *({{comp.note}})* {% endif %} {% if comp.doi %}[[doi]({{comp.doi}})]{% endif %} -->
{% if comp.media %} {% for item in comp.media %} {% if item.url %} [[{{item.name}}]({{item.url}}){:target="_blank"}] {% else %} [{{item.name}}] {% endif %}
{% endfor %}
{% endif %}
{% endfor %}


## Honors & Awards

### Scholarships

- **Doctoral College Scholarship**, tuition waiver with stipend, University of Surrey
- **Outstanding Graduate Students**, Northwestern Polytechnical University, 2020-2021
- **WuYaJun third class scholarship**, 2019
- **National Scholarship**, Northwestern Polytechnical University (top 1.5%), 2017 and 2018, **two consecutive years**
- **First-class Scholarship**, Northwestern Polytechnical University (top 14.7%), 2016 to 2019, **three consecutive years**
- **Gratitude to Scientists of Modern Times National Scholarship** (top 0.5%), 2018

### Selected Awards
- **First Prize** in the 2018 Chinaâ€™s National Robot Competition 
- **Honorable Mention** in the 2018 Mathematical Contest in Modeling
- **Second Prize** in the 2018 National Marine Vehicle Competition
- **First Prize** in 2018 Shaanxi Province Mathematical Contest in Modeling 
- **First Prize** in the 8th NWPU Intelligent Vehicle Competition 
- **First Prize** in 2018 NWPU C Language Programming competition 
- **First Prize** in the 2017 NWPU Mathematical Contest in Modeling 

### Qualifications
- China Conservatory of Music - Piano Program - **Level Ten** (highest)
- **TOEFL**: 108 (R: 29, L:27, S: 25, W:27; 2019/02)
- **GRE**: 322 (V:152, Q:170, W:3.5)
- **DET**: 130 (Literacy: 135, Comprehension: 135, Conversation:110, Production: 110)

## Teaching Assistance
- EEE3008 Fundamentals of DSP, University of Surrey, 2022/23 Semester 1
- EEE1033 Computer and Digital Logic, University of Surrey, 2022/23 Semester 1
- EEEM068 Applied Machine Learning, University of Surrey, 2022/23 Semester 2

<!-- <hr style="height:2px;border:none;color:#333;background-color:#333;" /> -->

<!-- ## Updates from my twitter -->

## Papers

<p style="color: red; font-weight: bold;">Click the image to zoom in and zoom out</p>

ðŸ‘¤ *stands for first author*

<hr>

{% assign thumbnail="left" %}
{% for pub in page.pubs %}

{% if pub.images %}
{% for img in pub.images %}
  {% include image.html url=img.url caption=img.caption height="80px" width="120px" align=thumbnail %}
{% endfor %}
{% endif %}
<!-- [**{{pub.title}}**]({% if pub.internal %}{{pub.url | prepend: site.baseurl}}{% else %}{{pub.url}}{% endif %})<br /> -->
**{{pub.title}}**<br />
{{pub.author}}<br />
*{{pub.journal}}* {% if pub.note %} *({{pub.note}})* {% endif %} {% if pub.year %} *{{pub.year}}* {% endif %} {% if pub.doi %}[[doi]({{pub.doi}})]{% endif %}
{% if pub.media %} {% for item in pub.media %} {% if item.url %} [[{{item.name}}]({{item.url}}){:target="_blank"}] {% else %} [{{item.name}}] {% endif %}
{% endfor %}
{% endif %}
{% if pub.additional %}
<div>
    <div class="button">Additional Informations</div>
    <ul class="list">
      {% for add in pub.additional %}
        <li>{{ add.content }}</li>
      {% endfor %}
    </ul>
</div>
{% endif %}
<hr>
{% endfor %}


{% include twitter.html %}

<!--Hyperlinks -->
[School of Computer Science]: https://jsj.nwpu.edu.cn/en/Home.htm
[NWPU]: https://en.nwpu.edu.cn/
[Google Scholar]: https://scholar.google.com/citations?user=g3O4lJMAAAAJ
[Github]: https://github.com/haoheliu
[500px]: https://500px.com/p/changersunjd?view=photos
[Centre for Vision Speech and Signal Processing]: https://www.surrey.ac.uk/centre-vision-speech-signal-processing
[Prof. Mark D. Plumbley]: https://www.surrey.ac.uk/people/mark-plumbley
[Prof. Wenwu Wang]: http://personal.ee.surrey.ac.uk/Personal/W.Wang/
[BBC R&D]: https://www.bbc.co.uk/rd
[AI for Sound]: https://ai4s.surrey.ac.uk/
[BBC Sound Effect Library]: https://sound-effects.bbcrewind.co.uk/
[Prof. Lei Xie]: https://scholar.google.com/citations?user=Qddov9wAAAAJ&hl=en
[NaturalSpeech]: https://speechresearch.github.io/naturalspeech/
[AudioLDM]:https://audioldm.github.io/
[VoiceFixer]:https://github.com/haoheliu/voicefixer
[CWS-PResUNet]:https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet
[NVSR]:https://github.com/haoheliu/ssr_eval
[DiffRes]: https://github.com/haoheliu/diffres-python
[Xu Tan]: https://scholar.google.com/citations?user=tob-U1oAAAAJ&hl=zh-CN
[Qiuqiang Kong]: https://qiuqiangkong.github.io/
[DCASE 2022 Challenge]: https://dcase.community/challenge2022/
[Prof. DeLiang Wang]: https://scholar.google.com/citations?user=yO59sggAAAAJ&hl=en
