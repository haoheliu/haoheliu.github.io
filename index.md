---
layout: page
title: Haohe Liu åˆ˜æ¿ èµ«
permalink: /
   
education:
    - title: "Centre for Vision, Speech and Signal Processing @ University of Surrey, UK, 01/2022 - 06/2025"
      image: "/images/surrey_logo.png"
      comment: "-- PhD in Vision, Speech and Signal Processing; Main supervisor: [Prof. Mark D. Plumbley]<br/>
                -- With a studentship from the CVSSP and the EPSRC Grant EP/T019751/1 AI for Sound<br/>
                -- 2024 Postgraduate Researcher of the Year Award - University of Surrey, CSEE"
    # - title: "Department of Computer Science and Engineering @ The Ohio State University, US, 01/2021 - 01/2022"
    #   image: "images/Ohio_State_University_seal.svg.png"
    #   comment: "-- PhD in Artificial Intelligence, Quit; advisor: [Prof. DeLiang Wang]<br/>
    #             -- GPA: 4.0/4.0"
    - title: "School of Computer Science @ Northwestern Polytechnical University, China, 09/2016 - 07/2020"
      image: "/images/nwpu.png"
      comment: "-- Bachelor of Engineering, Outstanding graduate, Computer Science and Technology; Supervisor: [Prof. Lei Xie]<br/>
                -- GPA: 3.8/4.0 (Top 5%)"

competitions:
    - title: First place
      author:  "Yi Yuan, **Haohe Liu**, Xubo Liu, Xiyuan Kang, Mark D.Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 7:Foley Sound Synthesis"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  "https://dcase.community/documents/challenge2023/technical_reports/DCASE2023_Yi_67_t7.pdf"
        - name: "Demo"
          url: "https://yyua8222.github.io/dcase_2023_t7_demo/"
        - name: "Code"
          url: "https://github.com/yyua8222/Dcase2023_task7"
        - name: "leaderboard"
          url: "https://dcase.community/challenge2023/task-foley-sound-synthesis-results"  
          
    - title: Second place
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE Challenge Task 5:Few-shot Bioacoustic Event Detection"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2207.07773
        - name: "Code"
          url: "https://github.com/haoheliu/DCASE_2022_Task_5"
        - name: "leaderboard"
          url: "https://dcase.community/challenge2022/task-few-shot-bioacoustic-event-detection-results"  

    - title: Second place on vocal score and fifth place on overall score
      author:  "**Haohe Liu** and Qiuqiang Kong and Jiafeng Liu"
      journal: "ISMIR Music Demixing Challenge"
      year:    "2021"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2112.04685
        - name: "Code"
          url: "https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet"
        - name: "Challenge details"
          url: "https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021"
        - name: "leaderboard"
          url: "https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards"    

    - title: Second place
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 6B: Language-Based Audio Retrieval"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_118_t6b.pdf
        - name: "Challenge details"
          url: "https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval" 

    - title: Third place
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE Challenge Task 6A: Automated Audio Captioning"
      year:    "2022"
      # image:   "/images/no.svg"
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf
        - name: "Challenge details"
          url: "https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval" 

news:
    shown:
      - time: 2025-10-20 &#128227;
        note: Best Technical Paper Award at the 159th AES Convention - Exploring the User Experience of AI-Assisted Sound Searching Systems for Creative Workflows [<a href="https://aes2.org/publications/elibrary-page/?id=23077">Paper</a>].
      - time: 2025-10-08 &#128100;
        note: Present at IEEE JSTSP Webinar - Overview of Special Issue on Neural Speech and Audio Coding [<a href="https://signalprocessingsociety.org/events/sps-jstsp-webinar-overview-special-issue-neural-speech-and-audio-coding">Website</a>].
      - time: 2025-06-12 &#128227; 
        note: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing! - AudioSetCaps - An Enriched Audio-Caption Dataset using Automated Generation Pipeline with Large Audio and Language Models
      - time: 2025-06-09 &#128188;
        note: Started my new role as a Research Scientist of Meta AI, Redmond, WA, USA.
      - time: 2025-05-30 &#129495;
        note: Grand challenge we are organising is officially launched at the 2025 Asia Pacific Signal and Information Processing Association Annual Summit and Conference - "City and Time-Aware Semi-supervised Acoustic Scene Classification" - [<a href="https://www.apsipa2025.org/wp/grand-challenge/">challenge website</a>]
      - time: 2025-05-23 &#128227; 
        note: Accepted by INTERSPEECH 2025 - EnvSDD - Benchmarking Environmental Sound Deepfake Detection.
      - time: 2025-05-04 &#128227; 
        note: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing! - Zero-Shot Audio Captioning Using Soft and Hard Prompts
      - time: 2025-04-22 &#128227; 
        note: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing! - WavJourney - Compositional Audio Creation with Large Language Models
      - time: 2025-03-04 &#128100;
        note: Poster presentation at the Launch of UK AI Hub in Generative Models [<a href="https://www.genai.ac.uk/news-feed/gen-ai-research-poster-exhibition">Website</a>].
      - time: 2025-01-01 &#128227; 
        note: FlowSep is accepted by the IEEE International Conference on Acoustics Speech and Signal Processing!
      - time: 2024-12-14 &#128100;
        note: Oral Presentation at the NeurIPS 2024 Audio Imagination Workshop - Topic - AudioSetCaps.
      - time: 2024-12-06 &#128227; 
        note: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing - Separate Anything You Describe - Congrat Xubo Liu et al.!
      - time: 2024-12-04 &#128227; 
        note: Accepted by Reviews in Aquaculture - Fish Tracking, Counting, and Behaviour Analysis in Digital Aquaculture - A Comprehensive Survey - Congrat Meng Cui et al.!
      - time: 2024-11-25 &#128227; 
        note: Accepted by IEEE Transactions on Automation Science and Engineering - Multimodal Fish Feeding Intensity Assessment in Aquaculture - Congrat Meng Cui et al.!
      - time: 2024-11-23 &#127942;
        note: Deeply honored to receive the Post Graduate Researcher of the Year Award for CSEE! [<a href="https://www.linkedin.com/pulse/cvssp-researcher-awarded-prestigious-award-cvssp-8y4we">Linkedin Post</a>]
      - time: 2024-11-14 &#128100;
        note: Visited NWPU (my undergrad university) and gave a talk.
      - time: 2024-11-09 &#128100;
        note: Presentation at the Shanghai Jiao Tong University X-LANCE lab [<a href="https://www.bilibili.com/video/BV1JjmBYYEoW">Recording</a>].
      - time: 2024-10-30 &#128227; 
        note: The <a href="https://haoheliu.github.io/SemantiCodec/">SemantiCodec</a> is accepted by the IEEE Journal of Selected Topics in Signal Processing.
      - time: 2024-10-17 &#128100;
        note: Visited Telecom Paris and gave a talk - Latent Diffusion Model as a Versatile Coarse-to-Fine Audio Decoder.
      - time: 2024-06-21 &#128227; 
        note: One paper got accepted by ACM MM 2024 - FlashSpeech - Efficient Zero-Shot Speech Synthesis.
      - time: 2024-06-19 &#128100;
        note: Talk at Spotify - Introduced SemantiCodec - [<a href="https://github.com/haoheliu/haoheliu.github.io/blob/main/pdf/2024-06-19-semanticodec.pdf">Slides</a>].
      - time: 2024-05-16 &#128100;
        note: Talk at MIT CSAIL Spoken Language Systems group. Topic - Learning Audio Pattern with Latent Diffusion Model - [<a href="https://github.com/haoheliu/haoheliu.github.io/blob/main/pdf/Haohe_Liu_2024_05_16.pdf">Slides</a>].
      - time: 2024-05-10 &#128100;
        note: Guest Lecture at EEEM068 Applied Machine Learning, University of Surrey, Topic - Introduction to Audio Artificial Intelligence [<a href="https://github.com/haoheliu/haoheliu.github.io/blob/main/pdf/AML%20Guest%20Lecture.pdf">Slides</a>].
      - time: 2024-04-25 &#128227;
        note: Accepted by the Journal TASLP - IEEE Transactions on Audio Speech and Language Processing - AudioLDM 2
      - time: 2024-04-12 	&#128745;
        note: Attended ICASSP 2024 (Seoul, Korea)! Did an oral presentation there about the paper AudioSR.
      - time: 2024-03-31 &#128100;
        note: Organizing a special session "Generative AI for Media Generation" at 2024 IEEE International Workshop on Machine Learning for Signal Processing (MLSP) [<a href="https://2024.ieeemlsp.org/498-2">link to IEEE MLSP 2024</a>] 
      - time: 2024-03-11 &#128227; 
        note: Accepted by ICLR 2024 Workshop LLMAgents - WavCraft - "Audio Editing and Generation with Large Language Models".
      - time: 2024-03-06 &#128100;
        note: Invited talk at UK Acoustic Network - "Recent Progress and Applications of Audio Artificial Intelligence Technologies".
      - time: 2024-02-05 &#129495;
        note: The IEEE ICME grand challenge we are organizing is officially launched - "Semi-supervised Acoustic Scene Classification under Domain Shift" - [<a href="https://ascchallenge.xshengyun.com/">challenge website</a>], [<a href="https://github.com/JishengBai/ICME2024ASC">official baseline</a>], [<a href="https://arxiv.org/abs/2402.02694">paper</a>]    
      - time: 2024-02-05 &#128227;
        note: Accepted by IEEE Open Journal of Signal Processing - "Attention-Based End-to-End Differentiable Particle Filter for Audio Speaker Tracking".
      - time: 2024-01-31 &#128100;
        note: Present at Surrey Open Research Culture Event 2024 [<a href="https://www.youtube.com/watch?v=xmZJl8qOFWw">link to YouTube</a>] 
      - time: 2024-01-13 &#128227;
        note: The NaturalSpeech paper is accepted by the Journal - IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). 
    hidden:
      - time: 2023-12-13 &#128227;
        note: Four papers were accepted by ICASSP 2024 this year. Many thanks to the collaborators and the feedback from reviewers! 
      - time: 2023-12-12 
        note: Short-listed by the Open Research Award of the University of Surrey (only four proposals were shortlisted!).
      - time: 2023-12-09 &#128227;
        note: Accepted by AAAI 2024 - DiffRes (Learning the Spectrogram Temporal Resolution for Audio Classification).
      - time: 2023-12-09 &#128227;
        note: Accepted by NeurIPS  2023 Workshop on Machine Learning for Audio - Composing and Validating Large-Scale Datasets for Training Open Foundation Models for Audio.
      - time: 2023-11-01 &#128100;
        note: Remotely present my research at Meta.
      - time: 2023-10-11 &#128100;
        note: Presented recent research at Huawei Future Device Technology Summit, Helsinki, Finland.
      - time: 2023-09-20 	&#128745;
        note: Attended DCASE 2023 (Tampere, Finland)! Did a spotlight presentation. Receive Judges' award from the DCASE committee.
      - time: 2023-09-15 &#127775;
        note: Open-sourced AudioSR, a versatile audio super resolution system. The paper is under review.
      - time: 2023-08-10 &#127775;
        note: Open-sourced AudioLDM 2, an improved version of AudioLDM. The paper is under review.
      - time: 2023-06-10 	&#128745;
        note: Attended ICASSP 2023 (Rhodes, Greece)!
      - time: 2023-06-02 &#128227;
        note: Rank 1st place in DCASE Challenge 2023 Task 7 - Foley Sound Synthesis.
      - time: 2023-05-18 &#128227;
        note: Three papers are accepted by INTERSPEECH 2023!
      - time: 2023-05-11 &#128100;
        note: Visit Department of Engineering, University of Cambridge, UK, for presentation and discussions.
      - time: 2023-04-25 &#128227;
        note: AudioLDM is accepted by ICML, International Conference on Machine Learning.
      - time: 2023-04-14 &#128100;
        note: Remotely present my recent research to Chinese Academy of Science (ä¸­ç§‘é™¢å£°å­¦æ‰€)
      - time: 2023-04-10 &#128100;
        note: Remotely present my recent research to Gaoling School of Artificial Intelligence, Remin University of China (ä¸­å›½äººæ°‘å¤§å­¦é«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢)
      - time: 2023-03-08 &#128100;
        note: Gave a remote presentation about AudioLDM to Mila, University of montreal [<a href="https://www.youtube.com/watch?v=6qtL9_T8m3c&t=972s">link to recording</a>]
      - time: 2023-02-28 &#127775;
        note: Youtube coverage of AudioLDM [<a href="https://www.youtube.com/watch?v=_0VTltNYhao&list=LL&index=2k">link</a>]. Comment area is very interesting. Thanks MattVidPro AI!
      - time: 2023-02-26 &#127775;
        note: Github repos reach 2000 stars in total!
      - time: 2023-02-24 &#128100;
        note: Gave a remote presentation about AudioLDM to SAMI, ByteDance, China. Thanks Qiuqiang for the invitation!
      - time: 2023-02-23 &#127775;
        note: AudioLDM ranks Top 25 most liked space (Top 0.01%) on Hugging Face [<a href="https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation">link</a>].        
      - time: 2023-02-22 &#128100;
        note: Gave a presentation about AudioLDM at TikTok, London. Thanks Janne for organizing this event!
      - time: 2023-02-17 &#128100;
        note: Gave a remote presentation about AudioLDM to NetEase, China. Thanks Pengcheng for the invitation!
      - time: 2023-02-15 &#128100;
        note: Live steaming and presenting AudioLDM on WeChat (in Chinese), with 4000+ viewers! [<a href="pdf/AudioLDM_2023_02_15.pdf">slides</a>]
      - time: 2023-02-15 &#128227;
        note: A paper was accepted in ICASSP 2023.
      - time: 2023-02-13 &#128227;
        note: A Large Chinese Media (æœºå™¨ä¹‹å¿ƒ) report our AudioLDM [<a href="https://mp.weixin.qq.com/s/UlkAVWYNrkMGNqtoDuMAGQ">link</a>]
      - time: 2023-02-03 &#127775;
        note: AI album [<a href="https://www.latent.store/albums ">website</a>], generated by our proposed text-to-audio generation model AudioLDM!
      - time: 2022-11-03 	&#128745;
        note: Attend DCASE 2022 Workshop (Nancy, France)!
      - time: 2022-09-18 	&#128745;
        note: Attend INTERSPEECH 2022 (Incheon, Korea) remotely and present two papers!
      - time: 2022-09-16 &#128227;
        note: A paper was accepted in NeurIPS 2022.
      - time: 2022-09-15 &#128227;
        note: A paper was accepted in DCASE Workshop 2022.
      - time: 2022-07-01 &#128227;
        note: Great result in DCASE 2022 Challenge - 2nd in Task 5; 2nd in Task 6B; 3rd in Task 6A.
      - time: 2022-06-01 &#128227;
        note: Four papers were accepted in INTERSPEECH 2022.
      - time: 2022-05-15 &#128227;
        note: A papers was accepted in EUSIPCO 2022. 
      - time: 2021-11-12 &#128100;
        note: Presented our winner model CWS-PResUNet to the audience on 2021 ISMIR MDX workshop.
      - time: 2021-11-12 &#128100;
        note: Gave a tutorial talk (<a href="https://docs.google.com/presentation/d/1AnlvPYCcuUZ2AW-4Q4BNdakqzgajoe9ltr4QUAr2oWw/edit">slides</a>) on music source separation with Alexandre Defossez and Woosung Choi at the 2021 ISMIR MDX satellite event!
      - time: 2021-09-30 &#128100;
        note: Gave a talk on VENTURE å°†é—¨åˆ›æŠ• (In Chinese) about the voicefixer I developed recently! [<a href="https://www.techbeat.net/talk-info?id=586">link</a>]
      - time: 2021-08-19 &#128195;
        note: Accept the Ph.D. offer from the CVSSP, University of Surrey, with tuition fee waiver and stipend!
      - time: 2021-07-31 &#128227;
        note: Great result in 2021 MDX Challenge (41 teams and 609 participants in total) - 2nd in vocal separation score; 5th in overall score; 
      - time: 2021-07-09 &#128227;
        note: A paper was accepted in ISMIR 2021.
      - time: 2021-06-02 &#128227;
        note: A paper was accepted in INTERSPEECH 2021.
      - time: 2020-07-24 &#128227;
        note: A paper was accepted in INTERSPEECH 2020.

pubs:
    - title:   "ðŸ‘¤ Learning the Spectrogram Temporal Resolution for Audio Classification"
      author:  "**Haohe Liu**, Xubo Liu, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "AAAI"
      year:    "2024"
      images:   
        - caption: "DiffRes Architecture"
          url: "/images/diffres.png"
      media:
        - name: "Paper"
          url:  "https://arxiv.org/abs/2210.01719"
        - name: "Code"
          url:  https://github.com/haoheliu/diffres-python
          
    - title: "Synth-AC: Enhancing Audio Captioning with Synthetic Supervision"
      author:  "Feiyang Xiao, Qiaoxi Zhu, Jian Guan, Xubo Liu, **Haohe Liu**, Kejia Zhang, Wenwu Wang"
      journal: "arXiv preprint arXiv: 2309.09705"
      year:    "2023"

    - title: "Retrieval-Augmented Text-to-Audio Generation"
      author:  "Yi Yuan, **Haohe Liu**, Xubo Liu, Qiushi Huang, Mark D Plumbley, Wenwu Wang"
      journal: "International Conference on Acoustics, Speech, and Signal Processing (ICASSP)"
      year:    "2024"

    - title: "ðŸ‘¤ AudioSR: Versatile Audio Super-resolution at Scale"
      author:  "**Haohe Liu**, Ke Chen, Qiao Tian, Wenwu Wang, Mark D Plumbley"
      journal: "International Conference on Acoustics, Speech, and Signal Processing (ICASSP)"
      year:    "2024"
      images:  
        - caption: "Architecture"
          url: "images/audiosr_model_arch.png"
        - caption: "Result"
          url: "images/audiosr_table.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2309.07314
        - name: "Code"
          url: https://github.com/haoheliu/versatile_audio_super_resolution
        - name: "Project Page"
          url: https://audioldm.github.io/audiosr/
        - name: "Discord Community"
          url: https://discord.gg/PCws9edF
          
    - title: "ðŸ‘¤ MusicLDM: Enhancing Novelty in Text-to-music Generation using Beat-synchronous Mixup Strategies"
      author:  "Ke Chen\\*, Yusong Wu\\*, Haohe Liu\\*, Marianna Nezhurina, Taylor Berg-Kirkpatrick, Shlomo Dubnov"
      journal: "International Conference on Acoustics, Speech, and Signal Processing (ICASSP)"
      year:    "2024"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2308.01546
        - name: "Code"
          url: https://github.com/RetroCirce/MusicLDM
        - name: "Project Page"
          url: https://musicldm.github.io/
          
    - title: "Multimodal Fish Feeding Intensity Assessment in Aquaculture"
      author:  "Meng Cui, Xubo Liu, Haohe Liu, Zhuangzhuang Du, Tao Chen, Guoping Lian, Daoliang Li, Wenwu Wang"
      journal: "arXiv preprint arXiv: 2309.05058"
      year:    "2023"

    - title: "ðŸ‘¤ AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining"
      author:  "**Haohe Liu**, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley"
      journal: "arXiv preprint arXiv:2308.05734"
      year:    "2023"
      images:  
        - caption: "Architecture"
          url: "images/audioldm2.jpg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2308.05734
        - name: "Code"
          url: https://github.com/haoheliu/audioldm2
        - name: "Project Page"
          url: https://audioldm.github.io/audioldm2/
        - name: "HuggingFace Web Demo"
          url: https://huggingface.co/spaces/haoheliu/audioldm2-text2audio-text2music
        - name: "Discord Community"
          url: https://discord.gg/VAN3xetK

    - title: "Separate Anything You Describe"
      author:  "Xubo Liu, Qiuqiang Kong, Yan Zhao, **Haohe Liu**, Yi Yuan, Yuzhuo Liu, Rui Xia, Yuxuan Wang, Mark D Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv:2308.05037"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2308.05037
        - name: "Code"
          url:  https://github.com/Audio-AGI/AudioSep
        - name: "Project Page; Demo"
          url:  https://audio-agi.github.io/Separate-Anything-You-Describe/
          
    - title: "WavJourney: Compositional Audio Creation with Large Language Models"
      author:  "Xubo Liu, Zhongkai Zhu, **Haohe Liu**, Yi Yuan, Meng Cui, Qiushi Huang, Jinhua Liang, Yin Cao, Qiuqiang Kong, Mark D Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv:2307.14335"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2307.14335
        - name: "Code"
          url:  https://github.com/Audio-AGI/WavJourney
        - name: "Project Page; Demo"
          url:  https://audio-agi.github.io/WavJourney_demopage/

    - title: "Text-Driven Foley Sound Generation With Latent Diffusion Model"
      author:  "Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark D Plumbley, Wenwu Wang"
      journal: "DCASE Workshop 2023"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/pdf/2306.10359

    - title: "Universal Source Separation with Weakly Labelled Data"
      author:  "Qiuqiang Kong, Ke Chen, **Haohe Liu**, Xingjian Du, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Mark D. Plumbley"
      journal: "arXiv preprint arXiv:2305.07447"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2305.07447
        - name: "code"
          url: https://github.com/bytedance/uss

    - title: "E-PANNs: Sound Recognition Using Efficient Pre-trained Audio Neural Networks"
      author:  "Arshdeep Singh, **Haohe Liu**, Mark D Plumbley"
      journal: "arXiv preprint arXiv:2305.18665"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2305.18665

    - title: "Learning to Detect an Animal Sound from Five Examples"
      author:  "InÃªs Nolasco, Shubhr Singh, Veronica Morfi, Vincent Lostanlen, Ariana Strandburg-Peshkin, Ester VidaÃ±a-Vila, Lisa Gill, Hanna PamuÅ‚a, Helen Whitehead, Ivan Kiskin, Frants H Jensen, Joe Morford, Michael G Emmerson, Elisabetta Versace, Emily Grout, **Haohe Liu**, Dan Stowell"
      journal: "Ecological Informatics"
      year:    "2023"
      media:
        - name: "Paper"
          url:  https://www.sciencedirect.com/science/article/pii/S157495412300287X

    - title: "WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research"
      author:  "Xinhao Mei, Chutong Meng, **Haohe Liu**, Qiuqiang Kong, Tom Ko, Chengqi Zhao, Mark D. Plumbley, Yuexian Zou, Wenwu Wang"
      journal: "arXiv preprint arXiv:2303.17395"
      year:    "2023" 
      images:  
        - caption: "How we built the WavCaps"
          url: "images/wavcaps.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2303.17395
        - name: "Dataset Download"
          url: https://github.com/XinhaoMei/WavCaps

    - title: "ðŸ‘¤ Leveraging Pre-trained AudioLDM for Sound Generation: A Benchmark Study"
      author:  "Yi Yuan\\*, **Haohe Liu**\\*, Jinhua Liang, Xubo Liu, Mark D. Plumbley, Wenwu Wang"
      journal: "arXiv preprint arXiv: 2303.03857"
      year:    "2023" 
      images:  
        - caption: "Finetune on ESC50"
          url: "images/audioldm-esc50.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2303.03857

    - title:   "ðŸ‘¤ AudioLDM: Text-to-Audio Generation with Latent Diffusion Models"
      author:  "**Haohe Liu**\\*, Zehua Chen\\*, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley"
      journal: "International Conference on Machine Learning (ICML)"
      year:    "2023" 
      images:  
        - caption: "Model Architecture"
          url: "/images/AudioLDM-main.jpg"
      media:
        - name: "Page"
          url:  https://audioldm.github.io/
        - name: "Paper"
          url:  https://arxiv.org/abs/2301.12503
        - name: "arXiv"
          url: https://arxiv.org/abs/2207.02201
        - name: "Code"
          url: https://github.com/haoheliu/AudioLDM
        - name: "Evaluation Code"
          url: https://github.com/haoheliu/audioldm_eval
        - name: "Hugging Face Space"
          url: https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation
        - name: "Replicate API"
          url: https://replicate.com/haoheliu/audio-ldm 
        - name: "Others"
          url: "https://docs.google.com/document/d/1ZM6r3ZtJ4mdtsYaTtUSG3_LaiaSCUxvCf8UvCE2HRls/edit?usp=sharing"
      additional: 
        - content: "2023-03-08 AudioLDM have reached 1000 stars on Github!"
        - content: "2023-03-09 AudioLDM reaches 400 likes on Hugging Face! Currently rank the TOP 25 liked spaces!"

    - title:   "Adapting Language-Audio Models as Few-Shot Audio Learners"
      author:  "Jinhua Liang, Xubo Liu, **Haohe Liu**, Huy Phan, Emmanouil Benetos, Mark D. Plumbley, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      # media:
      #   - name: "Paper"
      #     url:  https://arxiv.org/abs/2210.16428

    - title:   "ðŸ‘¤ Ontology-aware Learning and Evaluation for Audio Tagging"
      author:  "**Haohe Liu**, Qiuqiang Kong, Xubo Liu, Xinhao Mei, Wenwu Wang, Mark D. Plumbley"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      images: 
        - caption: "Main idea"
          url: "images/ontology-based-map.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2211.12195

    - title:   "Visually-awared Audio Captioning with Adaptive Audio-Visual Attention"
      author:  "Xubo Liu\\*, Qiushi Huang\\*, Xinhao Mei\\*, **Haohe Liu**, Qiuqiang Kong, Jianyuan Sun, Ko Tom, Yu Zhang, Lilian H. Tang, Mark D. Plumbley, Volkan KÄ±lÄ±c4, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2023"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2210.16428

    - title:   "Simple Pooling Front-ends For Efficient Audio Classification"
      author:  "Xubo Liu, **Haohe Liu**, Qiuqiang Kong, Xinhao Mei, Mark D. Plumbley, Wenwu Wang"
      journal: "IEEE International Conference on Acoustics, Speech, and Signal Processing"
      year:    "2023"
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2210.00943

    - title:   "ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech"
      author:  "Zehua Chen, Yihan Wu, Yichong Leng, Jiawei Chen, **Haohe Liu**, Xu Tan, Yang Cui, Ke Wang, Lei He, Sheng Zhao, Jiang Bian, Danilo Mandic"
      journal: "arXiv preprint arXiv:2212.14518"
      year:    "2022"
      images:
        - caption: "Pipline"
          url: "images/DiffSkinpipeline.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2212.14518"
        - name: "Demo"
          url: "https://resgrad1.github.io/"  

    - title:   "ðŸ‘¤ Surrey System for DCASE 2022 Task 5: Few-shot Bio-acoustic Event Detection with Segment-level Metric Learning"
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 2nd place in DCASE 2022 Challenge Task 5:Few-shot Bioacoustic Event Detection."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Haohe_85_5.pdf

    - title:   "Automated Audio Captioning with Keywords Guidance"
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 3rd place in DCASE 2022 Challenge Task 6A: Automated Audio Captioning."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf
      additional:
        - content: "System based on this method ranks 3nd in DCASE 2022 Challenge Task 6A"

    - title:   "Language-Based Audio Retrieval with Pre-trained Models"
      author:  "Xinhao Mei, Xubo Liu, **Haohe Liu**, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang"
      journal: "DCASE2022 Challenge Technical Report 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      note: "Ranked 3rd place in DCASE 2022 Challenge Task 6B: Language-Based Audio Retrieval."
      media:
        - name: "Report"
          url:  https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Mei_118_t6b.pdf
      additional:
        - content: "System based on this method ranks 2nd in DCASE 2022 Challenge Task 6B"


    - title:   "ðŸ‘¤ Segment-level Metric Learning for Few-shot Bioacoustic Event Detection"
      author:  "**Haohe Liu**, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Wenwu Wang, Mark D. Plumbley"
      journal: "DCASE Workshop 2022"
      year:    "2022"
      # image:   "/images/no.svg"
      images: 
        - caption: "Framework"
          url: "images/dcase2022_main.png"
        - caption: "Ranking"
          url: "images/dcase2022_t5.png"
      media:
        - name: "Paper"
          url:  https://arxiv.org/abs/2207.07773
        - name: "Code"
          url: "https://github.com/haoheliu/DCASE_2022_Task_5"
      additional:
        - content: "System based on this method ranks 2nd in DCASE 2022 Challenge Task 5"

    - title:   "BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis"
      author:  "Yichong Leng, Zehua Chen, Junliang Guo, **Haohe Liu**, Jiawei Chen, Xu Tan, Danilo Mandic, Lei He, Xiang-Yang Li, Tao Qin, Sheng Zhao, Tie-Yan Liu"
      journal: "Conference on Neural Information Processing Systems (NeurIPS)"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      images: 
        - caption: "Model Architecture"
          url: "images/BinarualGrad.png"
      media:
        - name: "Page"
          url:  https://speechresearch.github.io/binauralgrad/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2205.14807" #"https://doi.org/10.1109/TCSVT.2022.3143151"

    - title:   "ðŸ‘¤ NaturalSpeech: End-to-End Text-to-Speech Synthesis with Human-Level Quality"
      author:  "Xu Tan\\*, Jiawei Chen\\*, Haohe Liu\\*, Jian Cong, Chen Zhang, Yanqing Liu, Xi Wang, Yichong Leng, Yuanhao Yi, Lei He, Frank Soong, Tao Qin, Sheng Zhao, Tie-Yan Liu"
      journal: "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)"
      year:    "2022"
      note: under review
      # image:   "/images/no.svg"
      images:
        - caption: "Model Architecture"
          url: "images/NaturalSpeech.png"
      media:
        - name: "Page and demo"
          url:  https://speechresearch.github.io/naturalspeech/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2205.04421" #"https://doi.org/10.1109/TCSVT.2022.3143151"

    - title:   "ðŸ‘¤ VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration"
      author:  "**Haohe Liu**\\*, Xubo Liu\\*, Qiuqiang Kong, Qiao Tian, Yan Zhao, Deliang Wang, Chuanzeng Huang, Yuxuan Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Page"
          url:  https://haoheliu.github.io/demopage-voicefixer/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2204.05841"
        - name: "Code"
          url:  "https://github.com/haoheliu/voicefixer"         

    - title:   "ðŸ‘¤ VoiceFixer: Toward General Speech Restoration with Neural Vocoder"
      author:  "**Haohe Liu**, Qiuqiang Kong, Qiao Tian, Yan Zhao, Deliang Wang, Chuanzeng Huang, Yuxuan Wang"
      journal: "arXiv preprint arXiv:2109.13731"
      year:    "2021"
      doi:     
      images:   
        - caption: "VoiceFixer Architecture"
          url: "images/VoiceFixer.png"
      media:
        - name: "Page"
          url:  https://haoheliu.github.io/demopage-voicefixer/
        - name: "Paper"
          url:  "https://arxiv.org/abs/2204.05841"
        - name: "Code"
          url:  "https://github.com/haoheliu/voicefixer"  
      additional: 
        - content: "2023-03-02 VoiceFixer reaches 400 stars on Github!"

    - title:   "ðŸ‘¤ Neural Vocoder is All You Need for Speech Super-resolution"
      author:  "**Haohe Liu**, Woosung Choi, Xubo Liu, Qiuqiang Kong, Qiao Tian, DeLiang Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      images:
        - caption: "Architecture"
          url: "images/nvsr-main.png"
        - caption: "Example"
          url: "images/nvsr-example.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.15147"
        - name: "Code"
          url: "https://github.com/haoheliu/ssr_eval"

    - title:   "Multiple Speakers Tracking with Audio and Visual Signals"
      author:  "Jinzheng Zhao, Peipei Wu, Xubo Liu, Shidrokh Goudarzi, **Haohe Liu**, Yong Xu, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      media:
        - name: "Paper"
          url:  "http://personal.ee.surrey.ac.uk/Personal/W.Wang/papers/ZhaoWLGLXW_INTERSPEECH_2022.pdf"

    - title:   "Separate What You Describe: Language-Queried Audio Source Separation"
      author:  "Xubo Liu, **Haohe Liu**, Qiuqiang Kong, Xinhao Mei, Jinzheng Zhao, Qiushi Huang, Mark D. Plumbley, Wenwu Wang"
      journal: "INTERSPEECH"
      year:    "2022"
      doi:     
      images:
        - caption: "Framework"
          url: "images/LASS-main.png"
        - caption: "Example"
          url: "images/LASS-example.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.15147"
        - name: "Code"
          url: "https://github.com/liuxubo717/LASS"

    - title:   "Leveraging Pre-trained BERT for Audio Captioning"
      author:  "Xubo Liu, Xinhao Mei, Qiushi Huang, Jianyuan Sun, Jinzheng Zhao, **Haohe Liu**, Mark D. Plumbley, Volkan KÄ±lÄ±c, Wenwu Wang"
      journal: "EUSIPCO"
      year:    "2022"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2203.02838"

    - title:   "ðŸ‘¤ CWS-PResUNet: Music Source Separation with Channel-wise Subband Phase-aware ResUNet"
      author:  "**Haohe Liu** and Qiuqiang Kong and Jiafeng Liu"
      journal: "ISMIR Music Demixing Workshop"
      year:    "2021"
      doi:     
      images:   
        - caption: "Ranking" 
          url: "images/ismir_challenge_ranks.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2112.04685"
      additional:
        - content: "Ranking in 2021 ISMIR Music Demixing Challenge (611 participants): vocal score (2nd), overall performance (5th). "

    - title:   "Decoupling Magnitude and Phase Estimation with Deep ResUNet for Music Source Separation"
      author:  "Qiuqiang Kong, Yin Cao, **Haohe Liu**, Keunwoo Choi, Yuxuan Wang"
      journal: "ISMIR"
      year:    "2021"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2109.05418"

    - title:   "Speech Enhancement with weakly labeled data from audioset"
      author:  "Qiuqiang Kong, **Haohe Liu**, Xingjian Du, Li Chen, Rui Xia, Yuxuan Wang"
      journal: "INTERSPEECH"
      year:    "2021"
      doi:     
      # image:   "/images/no.svg"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2008.05216"


    - title:   "ðŸ‘¤ Channel-wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music"
      author:  "**Haohe Liu**, Lei Xie, Jian Wu, Geng Yang"
      journal: "INTERSPEECH"
      year:    "2020"
      doi:     
      images:   
        - caption: "Motivation"
          url: "images/cws-intuition.png"
        - caption: "Architecture"
          url: "images/cws-architecture.png"
      media:
        - name: "Paper"
          url: "https://arxiv.org/abs/2102.09971"
        - name: "Code"
          url: "https://github.com/haoheliu/Subband-Music-Separation"
        - name: "Demo"
          url: "https://haoheliu.github.io/Channel-wise-Subband-Input/"

---

<!-- About me -->

[![GitHub stars](https://img.shields.io/github/stars/haoheliu?style=social)](https://github.com/haoheliu) &nbsp;&nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/LiuHaohe?style=social)](https://twitter.com/LiuHaohe) &nbsp;&nbsp; [![LinkedIn](https://img.shields.io/badge/-LinkedIn-black.svg?style=flat-square&logo=linkedin&colorB=0077B5)](https://www.linkedin.com/in/haohe-liu-4483a71a4/) &nbsp;&nbsp; [![Google Scholar](https://img.shields.io/badge/Google-Scholar-blue?style=flat-square&logo=google-scholar)](https://scholar.google.com/citations?user=g3O4lJMAAAAJ)

Email: *haohe.liu AT surrey dot ac dot uk*

{% include image.html url="images/haohe_paris.jpg" caption="At the Pont de Bir-Hakeim, Paris (August 2024)" width="190px" align="right" %}

I'm working as a Research Scientist at Meta, Redmond, WA, USA. Iâ€™m also a final year PhD student at the [Centre for Vision Speech and Signal Processing] (CVSSP), University of Surrey. At surrey, I was fortunate to be supervised by [Prof. Mark D. Plumbley], co-supervised by [Prof. Wenwu Wang]. And Iâ€™m lucky to be jointly funded by [BBC R&D] and the Doctoral College. I was a team member of the EPSRC [AI for Sound] Project (EP/T019751/1). 

<!-- In the CVSSP, Iâ€™m working as part of the [AI for Sound] project to develop new methods for automatic labelling of sound environments and events in broadcast audio, assisting production staff in finding and searching through content and helping the general public access archive content.  -->
<!-- Iâ€™m also working closely with BBC R&D Audio Team on putting our audio recognition algorithms into production, such as generating machine tags in [BBC sound effect library]. -->

## Research highlights

My research includes tasks related to the audio generative model, source separation, quality enhancement, and recognition, appeared in journals and conferences such as TPAMI, TASLP, JSTSP, ICML, AAAI, NeurIPS, INTERSPEECH, and ICASSP.

I'm the first author of paper such as AudioLDM, AudioLDM 2, NaturalSpeech, VoiceFixer, SemantiCodec, MusicLDM, AudioSR, etc., with around 3000 citations. Most of my research studies are open-sourced. My open-source projects/checkpoints on GitHub have received over 9500 stars.

Highlighted research performed as the first author:

- Text-to-audio generation model: [AudioLDM] and [AudioLDM2].
- Ultra-low bitrate audio codec: [Semanticodec]
- Audio super-resolution model on any audio type and any sampling rate: [AudioSR].
- First text-to-speech model that achieves on par CMOS with human recording: [NaturalSpeech].
- Restore the quality of human speech signal regardless of how the signal is degraded: [VoiceFixer].
- The music source separation system that achieves leading performance on Music Demixing Challenge 2021: [CWS-PResUNet].
- Speech super-resolution model: [NVSR].
- A module that makes the temporal-resolution of the spectrogram differentiable for efficient audio classification: [DiffRes].
- Few-shot bioacoustic detection: The 2nd ranking system in the [DCASE 2022 Challenge] Task 5.

<!-- **Check out my [papers gallery](#papers){:target="_self"} for more information.** -->
Please refer to my Google Scholar Page for the full publication list: [![Google Scholar](https://img.shields.io/badge/Google-Scholar-blue?style=flat-square&logo=google-scholar)](https://scholar.google.com/citations?user=g3O4lJMAAAAJ)

## Recent News
<ul>
  {% for new in page.news.shown %}
    <li> {{new.time}} {{new.note}} </li>
  {% endfor %}
  <span id="points">...</span>
  <span id="moreText"> 
    {% for new in page.news.hidden %}
      <li> {{new.time}} {{new.note}} </li>
    {% endfor %}
  </span>
</ul>
<button onclick="toggleText()" id="textButton" class="showbutton"> Show More </button>

## Educations

{% assign thumbnail="left" %}
{% for edu in page.education %}
{% if edu.image %}
{% include image_original.html url=edu.image caption="" width="70px" align=thumbnail %}
{% endif %}
**{{edu.title}}** <br/>
{{ edu.comment }}
{% endfor %}


## Community Services

### Workshop/Challenge Organizations

- Co-organizer of the special session: "[Generative AI for Media Generation](https://2024.ieeemlsp.org/498-2/)" at 2024 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), London, UK.
- Co-organizer of the [IEEE 2024 ICME Grand Challenge](https://2024.ieeeicme.org/grand-challenge-proposals/) "[Semi-supervised Acoustic Scene Classification under Domain Shift](https://arxiv.org/abs/2402.02694)"

### Talks
- **2024:** MIT CSAIL Spoken Language Systems group (16 May), UK Acoustic Network (6 March), [Spotify (20 June)](https://youtu.be/wuueGced_Pg), TÃ©lÃ©com Paris Listen Lab (17 Oct), Shanghai Jiao Tong University (9 Nov)
- **2023:** NetEase (17 Feb), TikTok (22 Feb), ByteDance (24 Feb), [Mila - Quebec AI Institute](https://www.youtube.com/watch?v=6qtL9_T8m3c) (26 Feb), Chinese Academy of Science (14 April),  Remin University of China (4 Oct), University of Cambridge (11 May), Huawei Helsinki R&D (11 Oct), Meta FAIR (1 Nov)

### Conference Oral Presentations
- 2024 Conference on Neural Information Processing Systems
- 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing
- 2023 IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events
- 2021: A Tutorial on Music Source Separation, [ISMIR Music Demixing Workshop](https://www.youtube.com/watch?v=TntPVZ4ajIk&t=291s), Alexandre DÃ©fossez, Woosung Choi, Haohe Liu (12 Nov)

### Reviewer Services
I serve as a regular reviewer for the following journals:

- IEEE/ACM Transactions on Audio Speech and Language Processing
- IEEE Transactions on Multimedia
- IEEE Signal Processing Letters
- IEEE Transactions on Circuits and Systems for Video Technology
- IEEE Transactions on Neural Networks and Learning Systems
- International Journal on Information Fusion

I also serve as a reviewer for the following conferences:

- International Conference on Learning Representations **2026**
- IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) **2024, 2025**
- International Conference on Computer Vision (ICCV) **2025**
- AAAI Conference on Artificial Intelligence **2026**
- INTERSPEECH **2023, 2024, 2025**
- International Conference on Learning Representations (ICLR) **2025**
- Conference on Neural Information Processing Systems (NeurIPS) **2024**
- ACM MultiMedia **2023, 2024**
- IEEE International Joint Conference on Neural Networks (IJCNN) **2025**
- IEEE International Conference on Multimedia & Expo (ICME) **2024, 2025**
- IEEE International Workshop on Machine Learning for Signal Processing (MLSP) **2024**
- IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) **2025**

## Competitions
<!-- - Second place in DCASE 2022 Challenge Task 5:Few-shot Bioacoustic Event Detection. [code][details][leaderboard]
- Second place on vocal score and fifth place on overall score in ISMIR 2021 Music Demixing Challenge. [code][details] [leaderboard]
- Third in DCASE 2022 Challenge Task 6A: Automated Audio Captioning.
- Third in DCASE 2022 Challenge Task 6B: Language-Based Audio Retrieval. -->

{% assign thumbnail="left" %}
{% for comp in page.competitions %}
{% if comp.image %}
{% include image.html url=comp.image caption="" height="100px" align=thumbnail %}
{% endif %}
<!-- [**{{pub.title}}**]({% if pub.internal %}{{pub.url | prepend: site.baseurl}}{% else %}{{pub.url}}{% endif %})<br /> -->
- **{{comp.title}}**, *{{comp.journal}}*, {% if comp.year %} *{{comp.year}}* {% endif %}<br />
{{comp.author}}<br />
<!-- {% if comp.note %} *({{comp.note}})* {% endif %} {% if comp.doi %}[[doi]({{comp.doi}})]{% endif %} -->
{% if comp.media %} {% for item in comp.media %} {% if item.url %} [[{{item.name}}]({{item.url}}){:target="_blank"}] {% else %} [{{item.name}}] {% endif %}
{% endfor %}
{% endif %}
{% endfor %}

## Teaching


- Guest Lecturer, EEEM068 Applied Machine Learning, University of Surrey, 2024
- Demonstrator, EEE3008 Fundamentals of DSP, University of Surrey, 2022/23 Semester 1
- Demonstrator, EEE1033 Computer and Digital Logic, University of Surrey, 2022/23 Semester 1
- Demonstrator, EEEM068 Applied Machine Learning, University of Surrey, 2022/23 Semester 2

<!-- <hr style="height:2px;border:none;color:#333;background-color:#333;" /> -->

<!-- ## Updates from my twitter -->

{% include image.html url="images/piano.jpg" caption="" width="250px" align="center" %}

<!-- {% include twitter.html %} -->

<!--Hyperlinks -->
[School of Computer Science]: https://jsj.nwpu.edu.cn/en/Home.htm
[NWPU]: https://en.nwpu.edu.cn/
[Google Scholar]: https://scholar.google.com/citations?user=g3O4lJMAAAAJ
[Github]: https://github.com/haoheliu
[500px]: https://500px.com/p/changersunjd?view=photos
[Centre for Vision Speech and Signal Processing]: https://www.surrey.ac.uk/centre-vision-speech-signal-processing
[Prof. Mark D. Plumbley]: https://www.surrey.ac.uk/people/mark-plumbley
[Prof. Wenwu Wang]: http://personal.ee.surrey.ac.uk/Personal/W.Wang/
[BBC R&D]: https://www.bbc.co.uk/rd
[AI for Sound]: https://ai4s.surrey.ac.uk/
[BBC Sound Effect Library]: https://sound-effects.bbcrewind.co.uk/
[AI for Sound]: https://ai4s.surrey.ac.uk/team.html
[Prof. Lei Xie]: https://scholar.google.com/citations?user=Qddov9wAAAAJ&hl=en
[NaturalSpeech]: https://speechresearch.github.io/naturalspeech/
[AudioLDM]:https://audioldm.github.io/
[Semanticodec]: https://haoheliu.github.io/SemantiCodec/
[AudioLDM2]: https://audioldm.github.io/audioldm2
[AudioSR]: https://audioldm.github.io/audiosr
[VoiceFixer]:https://github.com/haoheliu/voicefixer
[CWS-PResUNet]:https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet
[NVSR]:https://github.com/haoheliu/ssr_eval
[DiffRes]: https://github.com/haoheliu/diffres-python
[Xu Tan]: https://scholar.google.com/citations?user=tob-U1oAAAAJ&hl=zh-CN
[Qiuqiang Kong]: https://qiuqiangkong.github.io/
[DCASE 2022 Challenge]: https://dcase.community/challenge2022/
[Prof. DeLiang Wang]: https://scholar.google.com/citations?user=yO59sggAAAAJ&hl=en
